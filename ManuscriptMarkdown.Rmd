---
title             : "Cross frequency coupling of attentional EEG task under pain"
shorttitle        : "Cross Pain"
author: 
  - name          : "Patrick Skippen"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Neuroscience Research Australia, Barker St, Randwick, Australia"
    email         : "p.skippen@neura.edu.au"
  - name          : "David Seminowicz"
    affiliation   : "1"
  - name          : "Ali Mazaheri"
    affiliation   : "2"
  - name          : "Samantha Mallard"
    affiliation   : "1"
  - name          : "Siobhan Schabrun"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Neuroscience Research Australia, Randwick Australia"
  - id            : "2"
    institution   : "Where-ever Ali is, Country"
author_note: |
  
  
  
  Author's  contributions: DS and AM conceptualised the research plan and rationale. PS took the lead role in manuscript preparation, formulated the analysis plan, and undertook majority of the data analysis. SS xyz.
  The data and code used to create this manuscript can be found at https://osf.io/XXXX/
  This is version 1: 02/2020
abstract: |
  blah blah.
  
keywords          : ""
bibliography      : "r-references.bib"
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
draft             : no
lang              : "english"
class             : "man"
output            :
  papaja::apa6_pdf:
    latex_engine: xelatex
header-includes: #allows you to add in your own Latex packages
- \usepackage{float} #use the 'float' package
- \usepackage{caption}
- \floatplacement{figure}{H} #make every figure with caption = h
- \raggedbottom
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
editor_options: 
  chunk_output_type: console
---

\setlength{\abovedisplayskip}{-20pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\abovedisplayshortskip}{-30pt}
\setlength{\belowdisplayshortskip}{3pt}

```{r Packages and Libraries, message = FALSE, warning = FALSE, echo = FALSE}
# installs packages if necessary - MUST locate packages before knitting
.libPaths("./Packages")
Packages <- c("ggplot2","dplyr","reshape","wesanderson",
              "BayesFactor",
              "kableExtra","rmatio","Rmisc",
              "rmarkdown","data.table","devtools",
              "cowplot","dplyr","readr") # Slew of packages used here.

# # Install CRAN packages, if necessary
# if(sum(!Packages %in% rownames(installed.packages()))>=1){
# invisible(lapply(Packages,install.packages,dependencies=TRUE))
# }

# Library Packags
invisible(lapply(Packages,library,character.only=TRUE))

## Standard error function
stderr <- function(x, na.rm=FALSE) {
  if (na.rm) x <- na.omit(x)
  sqrt(var(x)/length(x))
}
## Formatting Number Function for tables and output
numformat <- function(x, digits = 2) { 
    ncode <- paste0("%.", digits, "f")
    sub("^(-?)0.", "\\1.", sprintf(ncode, x))
}

## Raincloud plot function
source("./Packages/RainCloudPlots-master/tutorial_R/R_rainclouds.R")

# Install Git Packages, if necessary
if(!"papaja" %in% rownames(installed.packages())) devtools::install_github("crsh/papaja")
# if(!"wordcountaddin" %in% rownames(installed.packages())) devtools::install_github("benmarwick/wordcountaddin", type = "source", dependencies = TRUE)

# References info
papaja::r_refs(file = "r-references.bib")

# Knitting options
knitr::opts_chunk$set(comment = NA)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.pos= "h")
```

# 1. Introduction

# 2. Methods
```{r Methods Set-up, echo=FALSE}
# As per the following document. Only CLP106 -> CLP 149 are useable
PainCodes <- read.csv("EEGIdentity.csv")
PainCodes$Subjidx <- paste("CLP",PainCodes$Subjidx,sep = "")

Subjidx <- dir(path = "Data/RejectData/",
               pattern = "CLP*")
# Remove CLP116_2 until we know what that's about.
Subjidx <- Subjidx[Subjidx != "CLP116_2"]

# Seperate into those with pain data and those without
pain_Subjidx <- Subjidx[unlist(
  lapply(Subjidx, function(px)
    file.exists(
      paste("Data/RejectData/", px, "/", px, "_p_BadChannels.txt",sep = "")
    )))]

# Reduce particpants down to finalised numbers
PainCodes <- PainCodes[PainCodes$Subjidx %in% Subjidx,]

Conditions <- c("np","p")
source('Functions/ExtractRT_MATLAB.R')

## Below code only runs the first time. If Output/Trial_list exsits it will simply load the data.
if(!file.exists("Output/Trial_list.RData")){
Trial.list <- list()
## Extract Trial.list
for(px in seq_along(Subjidx)){
  Trial.list[["np"]][[px]] <- ExtractTrialData(PartID = Subjidx[px],COND = "np")
  
}
names(Trial.list[["np"]]) <- Subjidx

# N.B - CLP116 is missing pain data
Subjidx_p <- Subjidx[-16]
for (px in seq_along(Subjidx)) {
  if (file.exists(paste(
    "../Data/",
    Subjidx[px],
    "/Behaviour/",
    paste(Subjidx[px], "p", sep = "_"),
    "_EventCodes.mat",
    sep = ""
  ))) {
    Trial.list[["p"]][[px]] <-
      ExtractTrialData(PartID = Subjidx[px], COND = "p")
  }
  else {
    Trial.list[["p"]][[px]] <- NA
  }
}
names(Trial.list[["p"]]) <- Subjidx

## Remove CLP116 pain data
Trial.list[["p"]][is.na(Trial.list[["p"]])] <- NULL

save(Trial.list,file = "Output/Trial_list.RData")

Trialdata <- rbind(data.table::rbindlist(Trial.list$np),
                 data.table::rbindlist(Trial.list$p))
write.csv(Trialdata,file = "Output/TrialData.csv",
          row.names = F)
}

## Load data
tmp = load("Output/Trial_list.RData")
Trialdata <- read.csv("Output/TrialData.csv")
Trialdata <- Trialdata[Trialdata$PartID %in% Subjidx,]

## check CTI and ITI values:
hist(Trialdata$CTI)
hist(Trialdata$ITI)
table(Trialdata$PartID[Trialdata$ITI>4000]) # CLP114 and CLP124 might need a look into for long ITIs

## Calculate summary variables and store in data frame
source('Functions/MethodsList.R')
Summdata <- MethodsList(Trialdata) # Can ignore warnings - RE: mean RT for miss trials/SD for 2 trials total
```

## 2.1. Participants
  A total of *XXX* participants were recruited for the study, recruited from *Insert here*. A total of `r length(unique(Summdata$PartID))` participants remained after data cleaning and exclusion as outlined below. These participants ranged in age from *X-Xyrs (mean +/- SD) and were X% Female*. The study confirmed to ethics approved by *Ethics board of study*. 

## 2.2. Procedure

### 2.2.1. Cross-modal Attention task

The Cross-modal Attention task requires participants to respond to either the position of a visual target or the pitch of an auditory target. Targets can appear simultaneously and so participants are presented with a cue to indicate the correct target in the upcoming trial. This version of the task consisted of three types of cues. Cues consisted of *Insert what cues looked like* presented on screen for *How long were cues presented?*. Cue *one* indicated the participant should respond to the position of the visual target. Cue *two* indicated that participants should respond to the pitch of the auditory target. These two cues occurred on `r round((1-(table(Trialdata$CueType)[[1]]/sum(table(Trialdata$CueType))))/2,1)*100`% of trials each. On the remaining `r round((table(Trialdata$CueType)[[1]]/sum(table(Trialdata$CueType))),1)*100`% of trials, participants received an ambiguous cue, which gave no information about the upcoming target. On these trials only one target was presented. Equal ratios of auditory and visual targets followed ambiguous cues (*I'm guessing this is true?*).

  Cues were displayed for 250ms and targets for 60ms [*Please confirm this is correct. Trigger codes did not specify exactly*]. The cue to target interval (CIT) jittered between `r round(min(Trialdata$CTI,na.rm=T),0)`-`r round(max(Trialdata$CTI,na.rm=T),0)` in steps of **XXX** (*Values for this change with participants. Some have maxes of ~800ms and min of ~700ms. Others (N = 3) have max ~1500 and min ~1400* **I beleive I have fixed this with removal of some px**). Each trial lasted approximately `r round(mean(Trialdata %>% group_by(PartID) %>% summarise(meanITI = mean(ITI,na.rm=T)) %>% .$meanITI),0)`, with a jitter of **XXX**.

### 2.2.2. EEG Recording
  Participants completed the aforementioned task with concurent EEG recording using a **XXXX** system, fitted to the standard 10-20 system. EEG was sampled at 500Hz and referenced to referenced to the Afz electrode. Peripheral recordings of galvantic skin conductance, heart rate, and respiration were taken.
  
## 2.3. Data Extraction
### 2.3.1. Behaivoural Data
  The extracted variables from the beahvioural data include mean and standard deviation of correct reaction times (RT), mean and standard deviation of erronous reaction times (RT~err~), percentage of errors of comission, and percentage of omission errors. For each condition (i.e., No-pain and Pain) these variables were extracted across the following groupings; Modality (Visual vs Auditory cues), Preparation (Cued vs Ambiguous trials), and Distraction (Present vs Absent distractors). 
  
### 3.3.2. EEG Data
```{r EEG summary}
## Calculate the summary stats of the EEG analysis. RE: trial counts, channel/component removal
EEGPreProc <- list()
# Read in data from .txt files

## Collate number of removed channels
EEGPreProc[["BadChan"]][["np"]] <- lapply(Subjidx,
                                          function(px)
                                            nrow(
                                              read.table(
                                                paste("Data/RejectData/",
                                                      px, "/",
                                                      px,
                                                      "_np_BadChannels.txt",
                                                      sep = ""),
                                                row.names = NULL,
                                                quote = "\"",
                                                comment.char = ""
                                              )
                                            ))

names(EEGPreProc[["BadChan"]][["np"]]) <- Subjidx

EEGPreProc[["BadChan"]][["p"]] <- lapply(pain_Subjidx,
                                         function(px)
                                           nrow(
                                             read.table(
                                               paste("Data/RejectData/",
                                                     px, "/",
                                                     px,
                                                     "_p_BadChannels.txt",
                                                     sep = ""),
                                               row.names = NULL,
                                               quote = "\"",
                                               comment.char = ""
                                             )
                                           ))

names(EEGPreProc[["BadChan"]][["p"]]) <- pain_Subjidx

# Both conditions together
EEGPreProc[["BadChan"]][["Both"]] <- setNames(mapply(c, EEGPreProc[["BadChan"]][["np"]][Subjidx], EEGPreProc[["BadChan"]][["p"]][Subjidx]), Subjidx)

# Both conditions averaged
EEGPreProc[["BadChan"]][["Average"]] <- lapply(Subjidx,function(x) mean(EEGPreProc[["BadChan"]][["Both"]][[x]])) 

## Summarise number of removed components
EEGPreProc[["RejComp"]][["np"]] <- lapply(Subjidx,
                                          function(px)
                                            nrow(
                                              read.table(
                                                paste("Data/RejectData/",
                                                      px, "/",
                                                      px,
                                                      "_np_RejectedComps.txt",
                                                      sep = ""),
                                                row.names = NULL,
                                                quote = "\"",
                                                comment.char = ""
                                              )
                                            ))

names(EEGPreProc[["RejComp"]][["np"]]) <- Subjidx

EEGPreProc[["RejComp"]][["p"]] <- lapply(pain_Subjidx,
                                         function(px)
                                           nrow(
                                             read.table(
                                               paste("Data/RejectData/",
                                                     px, "/",
                                                     px,
                                                     "_p_RejectedComps.txt",
                                                     sep = ""),
                                               row.names = NULL,
                                               quote = "\"",
                                               comment.char = ""
                                             )
                                           ))

names(EEGPreProc[["RejComp"]][["p"]]) <- pain_Subjidx

# Both conditions together
EEGPreProc[["RejComp"]][["Both"]] <- setNames(mapply(c, EEGPreProc[["RejComp"]][["np"]][Subjidx], EEGPreProc[["RejComp"]][["p"]][Subjidx]), Subjidx)

# Both conditions averaged
EEGPreProc[["RejComp"]][["Average"]] <- lapply(Subjidx,function(x) mean(EEGPreProc[["RejComp"]][["Both"]][[x]])) 

## Summarise number of removed trials
EEGPreProc[["RejTrial"]][["np"]][["Visual"]] <- lapply(Subjidx,
                                                       function(px)
                                                         read.table(
                                                           paste(
                                                             "Data/RejectData/",
                                                             px,
                                                             "/",
                                                             px,
                                                             "_np_RF_Proc_RejTrials.txt",
                                                             sep = ""
                                                           ),
                                                           row.names = NULL,
                                                           quote = "\"",
                                                           comment.char = ""
                                                         )[[1, 1]])

names(EEGPreProc[["RejTrial"]][["np"]][["Visual"]]) <- Subjidx

EEGPreProc[["RejTrial"]][["np"]][["Auditory"]] <- lapply(Subjidx,
                                                       function(px)
                                                         read.table(
                                                           paste(
                                                             "Data/RejectData/",
                                                             px,
                                                             "/",
                                                             px,
                                                             "_np_RF_Proc_RejTrials.txt",
                                                             sep = ""
                                                           ),
                                                           row.names = NULL,
                                                           quote = "\"",
                                                           comment.char = ""
                                                         )[[2, 1]])

names(EEGPreProc[["RejTrial"]][["np"]][["Auditory"]]) <- Subjidx

EEGPreProc[["RejTrial"]][["np"]][["Ambiguous"]] <- lapply(Subjidx,
                                                       function(px)
                                                         read.table(
                                                           paste(
                                                             "Data/RejectData/",
                                                             px,
                                                             "/",
                                                             px,
                                                             "_np_RF_Proc_RejTrials.txt",
                                                             sep = ""
                                                           ),
                                                           row.names = NULL,
                                                           quote = "\"",
                                                           comment.char = ""
                                                         )[[3, 1]])

names(EEGPreProc[["RejTrial"]][["np"]][["Ambiguous"]]) <- Subjidx


EEGPreProc[["RejTrial"]][["p"]][["Visual"]] <- lapply(pain_Subjidx,
                                                       function(px)
                                                         read.table(
                                                           paste(
                                                             "Data/RejectData/",
                                                             px,
                                                             "/",
                                                             px,
                                                             "_p_RF_Proc_RejTrials.txt",
                                                             sep = ""
                                                           ),
                                                           row.names = NULL,
                                                           quote = "\"",
                                                           comment.char = ""
                                                         )[[1, 1]])

names(EEGPreProc[["RejTrial"]][["p"]][["Visual"]]) <- pain_Subjidx

EEGPreProc[["RejTrial"]][["p"]][["Auditory"]] <- lapply(pain_Subjidx,
                                                       function(px)
                                                         read.table(
                                                           paste(
                                                             "Data/RejectData/",
                                                             px,
                                                             "/",
                                                             px,
                                                             "_p_RF_Proc_RejTrials.txt",
                                                             sep = ""
                                                           ),
                                                           row.names = NULL,
                                                           quote = "\"",
                                                           comment.char = ""
                                                         )[[2, 1]])

names(EEGPreProc[["RejTrial"]][["p"]][["Auditory"]]) <- pain_Subjidx

EEGPreProc[["RejTrial"]][["p"]][["Ambiguous"]] <- lapply(pain_Subjidx,
                                                       function(px)
                                                         read.table(
                                                           paste(
                                                             "Data/RejectData/",
                                                             px,
                                                             "/",
                                                             px,
                                                             "_p_RF_Proc_RejTrials.txt",
                                                             sep = ""
                                                           ),
                                                           row.names = NULL,
                                                           quote = "\"",
                                                           comment.char = ""
                                                         )[[3, 1]])

names(EEGPreProc[["RejTrial"]][["p"]][["Ambiguous"]]) <- pain_Subjidx

# Both conditions together
EEGPreProc[["RejTrial"]][["Both"]][["Visual"]] <- setNames(mapply(c, EEGPreProc[["RejTrial"]][["np"]][["Visual"]][Subjidx],                                                       EEGPreProc[["RejTrial"]][["p"]][["Visual"]][Subjidx]), Subjidx)

EEGPreProc[["RejTrial"]][["Both"]][["Auditory"]] <- setNames(mapply(c, EEGPreProc[["RejTrial"]][["np"]][["Auditory"]][Subjidx], EEGPreProc[["RejTrial"]][["p"]][["Auditory"]][Subjidx]), Subjidx)

EEGPreProc[["RejTrial"]][["Both"]][["Ambiguous"]] <- setNames(mapply(c, EEGPreProc[["RejTrial"]][["np"]][["Ambiguous"]][Subjidx], EEGPreProc[["RejTrial"]][["p"]][["Ambiguous"]][Subjidx]), Subjidx)

# Both conditions averaged
EEGPreProc[["RejTrial"]][["Average"]][["Visual"]] <- lapply(Subjidx,function(x) mean(EEGPreProc[["RejTrial"]][["Both"]][["Visual"]][[x]]))

EEGPreProc[["RejTrial"]][["Average"]][["Auditory"]] <- lapply(Subjidx,function(x) mean(EEGPreProc[["RejTrial"]][["Both"]][["Auditory"]][[x]]))

EEGPreProc[["RejTrial"]][["Average"]][["Ambiguous"]] <- lapply(Subjidx,function(x) mean(EEGPreProc[["RejTrial"]][["Both"]][["Ambiguous"]][[x]]))

## Total Trials Removed
EEGPreProc[["RejTrial"]][["Total"]] <- lapply(seq_along(Subjidx),
                                              function(x)
                                              sum(EEGPreProc[["RejTrial"]][["Average"]][["Visual"]][[x]],
                                              EEGPreProc[["RejTrial"]][["Average"]][["Auditory"]][[x]],
                                              EEGPreProc[["RejTrial"]][["Average"]][["Ambiguous"]][[x]]))

Perc_TrialsRemoved <- data.frame(Vis = (unlist(EEGPreProc[["RejTrial"]][["Average"]][["Visual"]])/120),
                            Aud = (unlist(EEGPreProc[["RejTrial"]][["Average"]][["Auditory"]])/120),
                            Amb = (unlist(EEGPreProc[["RejTrial"]][["Average"]][["Ambiguous"]])/60))
## Compare Cue Types on the percentage of removed trials
# format data
TrialsRemoved_test <- reshape2::melt(Perc_TrialsRemoved)
# Freq test
TR_ANOVA <- aov(value ~ variable, data = TrialsRemoved_test)
# Bayes test
BF_TR_ANOVA <- BayesFactor::anovaBF(value ~ variable, data = TrialsRemoved_test)
```
  An outline of the EEG pre-processing undertaken here is presented in Figure *X*. EEG data were first average referenced and high pass filtered at 1Hz using the *removeTrend* function. Line noise of 6Hz and its associated harmonics was removed using a notch filter before the *clean_artifacts* function was used to detect bad channels. Channels were marked for removal is there was noise greater than 4 standard deviations greater than the mean, 1/5th of the channel was flat, or correlations with other channels was lower than .8. This processed removed an average of `r round(mean(unlist(EEGPreProc$BadChan$Average)),2)` +/- `r round(sd(unlist(EEGPreProc$BadChan$Average)),2)` of channels. The results of this were visually inspected ad confirmed before data was subjected to ICA. Resulting components from the *run_ica* output was marked for removal with the the ICLabel algorthm, where compnents classifed greater than 75% eye, greater than 80% muscle, or greater than 90% heart, line, and channel were removed. Visual inspection confirmed the component removal and the ICA weights were saved for later referral.
  The final EEG data set was high pass filtered at 0.1Hz. Bad channels were removed and ICA weights were added to the data and bad components removed. An average of `r round(mean(unlist(EEGPreProc$RejComp$Average)),2)` +/- `r round(sd(unlist(EEGPreProc$RejComp$Average)),2)` copmonents were removed for each participant. Channels were then interpolated using *pop_interp* and data epoched 1.5s before the cue to 2.5s post-cue, for each cue seperately. EEGLABs extreme epoch noise detection using EEGLab's threshold & joint probability procedures was undertaken with the cut-off for amplitude set at 100uV **put in other stuff heree**. An average of `r round(mean(unlist(EEGPreProc$RejTrial$Average)),2)` +/- `r round(sd(unlist(EEGPreProc$RejTrial$Average)),2)` trials were removed using this procedure for each participant. Lastly, data were current source density transformed useing Fieldtrips *ft_scalpcurrentdensity* using the spline method.
  An average of `r round(mean(unlist(EEGPreProc[["RejTrial"]][["Total"]])),2)` +/- `r round(sd(unlist(EEGPreProc[["RejTrial"]][["Total"]])),2)` trials were removed for each participant. There was no influence of Cue Type on the percentage of trials removed, as shown with a one-way ANOVA (`r papaja::apa_print.aov(TR_ANOVA)$full_result$variable`). An equivilant Bayesian ANOVA showed evidence for the null (BF~10~ = `r round(extractBF(BF_TR_ANOVA)[[1]],3)`).
  Time freqeucny transform was undertaken closely following the advice of Cohen (2014; *check refrence*). In short, Morelt wavelets were created at different frequency dependent widths. Across the 80 linearlly spaced frequency bins between 3 and 30Hz, wavelets were created with widths between 6 and 10 cycles. In other words, smaller width wavelets were used for slower frequencies and larger width wavelets were used for faster frequncies. This allowed for the investigation of multiple freqency bands (i.e., both Theta and Alpha) with approximately the same resolution. The output of this process was baselined using a decibel conversion to the time period -500 to -200ms pre-cue. ERPs to each cue were taken for the time period up to 1 second post cue. To control for high frequency noise, the data were low pass filtered at 30Hz for the ERP analyis. ERPs were baselined -200ms to cue onset (i.e., 0ms).
  
## 2.4. Statistical Procedure
### 2.4.1. Behavioural Analysis
  The behavioural data of the C-MAT task was first assessed in the no pain condition. To explore the influence of Modality, Preparation, and Distraction, a large Bayesian ANOVA model comparing each of these was established. As error and omission rates were low overall and absent in some participants, these effects should be treated with caution. To test the presence or absence of an effect we first examined the overall best fit model by examining Bayes Factors of each model respective to the null model, which just includes a subject factor. If interactions are present we also assess the inclusion Bayes Factor, by controlling for matched models. The BF~inclusion~ describes the evidence for the inclusion of a specific factor (i.e., interaction) of the model, when controlling for the main effects. Any interactions were then explore using either one-way ANOVAs, or t-tests. The influence of pain on the aformentioned effects is then assesed by adding a Pain (No-Pain vs. Pain) factor to the overall model and exploring any possible interactions with the Pain factor using the aforementioned steps.
  
### 2.4.2. EEG Analysis
  
  
### 2.4.3. Determination of Effects
  This study useses a joint methodology of frequentist and Bayesian tests. Bayesian tests are preferred and used where ever possible. However, as some common methodologies used in this literature have not been adapted to Bayesian, we use frequentist statistics alonside the Bayesian tests. For example, cluster based permutations are often used in the high dimensionality space of EEG, where multiple electrodes, across multiple subjects are compared across time-frequency space. The method itself helps control for multiple comparisons, which to date has not been as effectively and efficiently implimented in Bayes. 
  
  
  *Another option is to do a linear model*
  For the ANOVA models on behavioural data with the default priors of Rouder, et al., (2012) and a 'medium' r scale of sqrt(2)/2. For *t-tests, blah blah is used...*
  Evidence cut-offs are used to assist in interpretation of Bayes factors. In line with Kass & Rafferty, (1995), we use the following cut-offs. A Bayes factor between 1/3 and 3 is considered ‘Equivocal’ (i.e., indicating more data are needed to obtain a clear outcome), between 1/20–1/3 and 3–20 is considered ‘Positive’, between 1/150–1/20 and 20–150 ‘Strong’, and Bayes factors < 1/150 and > 150 are considered ‘Very Strong’.

# 3. Results 
  Blah blah we first present yada yada
```{r Results Set-up, echo=FALSE}
#### Plotting RT ####
## Create plots to observe possible outliers, effects, interactions etc

## Colour-blind friendly pallatte - I use wesanderson for plotting, colour blind friendly for pubs
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7","#000000")

## We will plot four main comparisons on RT:
# Modality (Auditory vs Visual Targets)
# Preparation (Cued-targets vs Ambiguous Target; i.e., CueType)
# Interference/Distraction (Prescence vs Abscence of Targetsl; i.e., Distractor)
# Pain (Pain vs No-Pain; ie., Condition) - Compared across all of the above.

# source the function
source('Functions/RT_RainPlots.R')

# Change condition labels to plot better
levels(Trialdata$Condition) <- c("No Pain","Pain")

# Create list and loop through plots
if(!file.exists("Output/RT_Rainplots.RData")){
Plots <- list()
RT_comp_xvals <- c("Target","CueType","Distractor","Condition")
RT_comp_groupvals <- c("Accuracy","Target","CueType","Distractor","Condition")

for (i in seq_along(RT_comp_xvals)){
Plots[[RT_comp_xvals[i]]] <- lapply(RT_comp_groupvals,function(x) RT_RainPlot(data = Trialdata,
                                                                      xval = RT_comp_xvals[i],
                                                                      groupval = x))
names(Plots[[RT_comp_xvals[i]]]) <- RT_comp_groupvals
}
save(Plots,file = "Output/RT_Rainplots.RData")

}
# Else we just load the data - much faster
tmp = load(file = "Output/RT_Rainplots.RData")

#### Error Rates Calclations ####

# Create list of error rates on splits of interest
N_Trials <- list()
N_Trials[["Condition"]] <-
Trialdata %>% dplyr::group_by(PartID, Condition, Accuracy) %>% dplyr::tally() %>% dplyr::group_by(PartID,Condition) %>% dplyr::mutate(total = sum(n)) %>% dplyr::mutate(perc = (n/total)*100) %>% dplyr::select(-n,-total) %>% dplyr::filter(Accuracy!="Correct")

N_Trials[["CueType"]] <-
Trialdata %>% dplyr::group_by(PartID, CueType, Accuracy) %>% dplyr::tally() %>% dplyr::group_by(PartID,CueType) %>% dplyr::mutate(total = sum(n)) %>% dplyr::mutate(perc = (n/total)*100) %>% dplyr::select(-n,-total) %>% dplyr::filter(Accuracy!="Correct")

N_Trials[["Distractor"]] <-
Trialdata %>% dplyr::group_by(PartID, Distractor, Accuracy) %>% dplyr::tally() %>% dplyr::group_by(PartID,Distractor) %>% dplyr::mutate(total = sum(n)) %>% dplyr::mutate(perc = (n/total)*100) %>% dplyr::select(-n,-total) %>% dplyr::filter(Accuracy!="Correct")

N_Trials[["Target"]] <-
Trialdata %>% dplyr::group_by(PartID, Target, Accuracy) %>% dplyr::tally() %>% dplyr::group_by(PartID,Target) %>% dplyr::mutate(total = sum(n)) %>% dplyr::mutate(perc = (n/total)*100) %>% dplyr::select(-n,-total) %>% dplyr::filter(Accuracy!="Correct")

## Plot Errors and Omissions Data
# Create list and loop through plots
source('Functions/Error_RainPlots.R')
if(!file.exists("Output/Errors_Rainplots.RData")){
Error_comp_xvals <- "Accuracy"
Error_comp_groupvals <- c("Target","CueType","Distractor","Condition")

Err_Plots <- lapply(Error_comp_groupvals, function(x)
  Err_RainPlot(
  data = N_Trials[[x]],
  xval = "Accuracy",
  groupval = x
  ))
  names(Err_Plots) <- Error_comp_groupvals
  
  save(Err_Plots, file = "Output/Errors_Rainplots.RData")
}

# Else we just load the data - much faster
tmp = load(file = "Output/Errors_Rainplots.RData")

## Create SPSS/JASP ready dataframe for RT
Programdata <-
  reshape2::dcast(
    data = Trialdata,
    formula = PartID ~ Condition + CueType + Target + Distractor + Accuracy,
    fun.aggregate = mean,
    value.var = "RT"
)

# Write to file
write.csv(Programdata, file = "Output/Wide_RTdata.csv",
          row.names = F)

## Create SPSS/JASP ready dataframe for errors
N_Trials[["CueType"]]$CueType <- paste(N_Trials[["CueType"]]$CueType,"Cue",sep="")
N_Trials[["Condition"]]$Condition <- as.character(N_Trials[["Condition"]]$Condition)
N_Trials[["Distractor"]]$Distractor <- as.character(N_Trials[["Distractor"]]$Distractor)
N_Trials[["Target"]]$Target <- as.character(N_Trials[["Target"]]$Target)

for (i in seq_along(N_Trials)){
  names(N_Trials[[i]]) <- c("PartID","Variable","Accuracy","Perc")
}

## Way too difficult way to create data frame
Errorsdata <- data.frame(PartID = c(as.character(N_Trials$Condition$PartID),
                                    as.character(N_Trials$CueType$PartID),
                                    as.character(N_Trials$Distractor$PartID),
                                    as.character(N_Trials$Target$PartID)),
                         Variable = c(as.character(N_Trials$Condition$Variable),
                                    as.character(N_Trials$CueType$Variable),
                                    as.character(N_Trials$Distractor$Variable),
                                    as.character(N_Trials$Target$Variable)),
                         Accuracy = c(as.character(N_Trials$Condition$Accuracy),
                                    as.character(N_Trials$CueType$Accuracy),
                                    as.character(N_Trials$Distractor$Accuracy),
                                    as.character(N_Trials$Target$Accuracy)),
                         Perc = c(N_Trials$Condition$Perc,
                                    N_Trials$CueType$Perc,
                                    N_Trials$Distractor$Perc,
                                    N_Trials$Target$Perc)
                         )



```

## 3.1. Behavioural Results
```{r Table 1, echo=FALSE}
## Create formatted summary table of Behavioural results to support plots and analysis
VOI <- c("Target","CueType","Distractor")
RT_means <- list()
Error_means <- list()

for (i in VOI){
# Correct RT
RT_means[["Correct"]][[i]] <- Trialdata %>%
    dplyr::filter(Accuracy == "Correct") %>%
    dplyr::group_by(PartID, get(i), Condition) %>%
    dplyr::summarise(subjRT = mean(RT, na.rm = T)) %>%
    dplyr::group_by(`get(i)`, Condition) %>% 
    dplyr::summarise(RT = mean(subjRT, na.rm = T),
                     SD = sd(subjRT, na.rm = T)) %>% 
  dplyr::ungroup()
names(RT_means[["Correct"]][[i]]) <- c("Variable", "Condition","RT","SD")

# Error RT
RT_means[["Error"]][[i]] <- Trialdata %>%
    dplyr::filter(Accuracy == "Error") %>%
    dplyr::group_by(PartID, get(i), Condition) %>%
    dplyr::summarise(subjRT = mean(RT, na.rm = T)) %>%
    dplyr::group_by(`get(i)`, Condition) %>% 
    dplyr::summarise(RT = mean(subjRT, na.rm = T),
                     SD = sd(subjRT, na.rm = T)) %>% 
  dplyr::ungroup()
names(RT_means[["Error"]][[i]]) <- c("Variable", "Condition","Error RT","SD")

# Error Rates
Error_means[["Error"]][[i]] <- Trialdata %>% 
  dplyr::group_by(PartID, get(i), Accuracy, Condition) %>% 
  dplyr::tally() %>% 
  dplyr::group_by(PartID, `get(i)`, Condition) %>% 
  dplyr::mutate(total = sum(n)) %>% 
  dplyr::mutate(perc = (n /total) * 100) %>% 
  dplyr::select(-n, -total) %>% 
  dplyr::filter(Accuracy =="Error") %>% 
  dplyr::group_by(`get(i)`,Condition) %>% 
  dplyr::summarise(Errors = mean(perc, na.rm=T),
                   SD = sd(perc,na.rm = T)) %>% 
  dplyr::ungroup()
names(Error_means[["Error"]][[i]]) <- c("Variable", "Condition","Errors (%)","SD")

# Miss Rates
Error_means[["Miss"]][[i]] <- Trialdata %>% 
  dplyr::group_by(PartID, get(i), Accuracy, Condition) %>% 
  dplyr::tally() %>% 
  dplyr::group_by(PartID, `get(i)`, Condition) %>% 
  dplyr::mutate(total = sum(n)) %>% 
  dplyr::mutate(perc = (n /total) * 100) %>% 
  dplyr::select(-n, -total) %>% 
  dplyr::filter(Accuracy =="Miss") %>% 
  dplyr::group_by(`get(i)`,Condition) %>% 
  dplyr::summarise(Errors = mean(perc, na.rm=T),
                   SD = sd(perc,na.rm = T)) %>% 
  dplyr::ungroup()
names(Error_means[["Miss"]][[i]]) <- c("Variable", "Condition","Omissions (%)","SD")

}


# Format Table 1 - other option is to group RT, seperate to Errors/Omissions (table currently too big imo)
Tab1_RT <- dplyr::bind_rows(RT_means$Correct,
                      .id = "Effect")
Tab1_RT <- cbind(RT_means$Correct[RT_means$Correct])
Tab1_RTerr <- dplyr::bind_rows(RT_means$Error,
                      .id = "Effect")
Tab1_Err <- dplyr::bind_rows(Error_means$Error,
                      .id = "Effect")
Tab1_Miss <- dplyr::bind_rows(Error_means$Miss,
                      .id = "Effect")

np_Tab1 <- cbind(Tab1_RT[Tab1_RT$Condition=="No Pain",],
                 Tab1_RTerr[Tab1_RTerr$Condition=="No Pain",][c("Error RT", "SD")],
                 Tab1_Err[Tab1_Err$Condition=="No Pain",][c("Errors (%)", "SD")],
                 Tab1_Miss[Tab1_Miss$Condition=="No Pain",][c("Omissions (%)", "SD")]
)
np_Tab1$Condition <- NULL
np_Tab1$Effect <- NULL
                 
p_Tab1 <- cbind(Tab1_RT[Tab1_RT$Condition=="Pain",],
                 Tab1_RTerr[Tab1_RTerr$Condition=="Pain",][c("Error RT", "SD")],
                 Tab1_Err[Tab1_Err$Condition=="Pain",][c("Errors (%)", "SD")],
                 Tab1_Miss[Tab1_Miss$Condition=="Pain",][c("Omissions (%)", "SD")]
)
p_Tab1$Condition <- NULL
p_Tab1$Effect <- NULL

Table1 <- cbind(np_Tab1,p_Tab1)
names(Table1) <-
  c(
  "",
  "RT",
  "SD",
  "Error RT",
  "SD",
  "Errors (%)",
  "SD",
  "Omissions (%)",
  "SD",
  "Variable",
  "RT",
  "SD",
  "Error RT",
  "SD",
  "Errors (%)",
  "SD",
  "Omissions (%)",
  "SD"
  )
Table1$Variable <- NULL

# Paste the SD with the RT in brackets? - round to 2 digits


# Print Table 1
# Column headers for Condition
# Row Groupings for Modality, Cue Type, Distractor
kable(Table1, caption = "Table 1. Behavoural Summary Stats",digits = 2) %>%
  kable_styling("striped", full_width = F) %>%
 add_header_above(c(" " = 1, "No Pain" = 8, "Pain" = 8)) %>% 
  pack_rows("Modality", 1, 2) %>%
  pack_rows("Cue Type", 3, 5) %>% 
  pack_rows("Distractor",6, 7)

```

### 3.1.1. Modality Effects
Visual targets (`r round(mean(T1mean$Modality$RT[T1mean$Modality$Target=="Visual"]),2)` ± `r round(stderr(T1mean$Modality$RT[T1mean$Modality$Target=="Visual"]),2)`) were identified faster than auditory targets (`r round(mean(T1mean$Modality$RT[T1mean$Modality$Target=="Auditory"]),2)` ± `r round(stderr(T1mean$Modality$RT[T1mean$Modality$Target=="Auditory"]),2)`). The percentage of errer trials was higher for auditory targets compared to visual targets. Visual targets were incorrectly responded to on `r round(mean(T1err$Modality$ErrorRates[T1err$Modality$Target=="Visual"]),2)` ± `r round(stderr(T1err$Modality$ErrorRates[T1err$Modality$Target=="Visual"]),2)`% trials, while auditory targets had an error rate of `r round(mean(T1err$Modality$ErrorRates[T1err$Modality$Target=="Auditory"]),2)` ± `r round(stderr(T1err$Modality$ErrorRates[T1err$Modality$Target=="Auditory"]),2)`%. Given the low error rates, RTs to error trials were not examined here (but see Figure 1). Omissions across each target type was low (Visual = `r round(mean(T1omm$Modality$MissRates[T1err$Modality$Target=="Visual"],na.rm=T),2)`%, Auditory = `r round(mean(T1omm$Modality$MissRates[T1err$Modality$Target=="Visual"],na.rm=T),2)`%).

```{r Figureone, echo=FALSE, fig.cap = 'Violin plot of RT to visual and auditory targets. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean', message=FALSE}
Plots$Modality$Accuracy
```

### 3.1.2. Preparatory Effects
To examine the effect of preparation, reaction times of trials with informative cues were compared to trials with ambiguous cues. Correct trial RTs for auditory targets decreased from `r round(mean(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Ambiguous" & T1mean$PrepTarget$Target=="Auditory"]),2)` ± `r round(stderr(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Ambiguous" & T1mean$PrepTarget$Target=="Auditory"]),2)`ms for ambiguous cues to `r round(mean(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Auditory" & T1mean$PrepTarget$Target=="Auditory"]),2)` ± `r round(stderr(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Auditory" & T1mean$PrepTarget$Target=="Auditory"]),2)`ms for informative cues. For visual targets the average RT decreased from `r round(mean(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Ambiguous" & T1mean$PrepTarget$Target=="Visual"]),2)` ± `r round(stderr(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Ambiguous" & T1mean$PrepTarget$Target=="Visual"]),2)` ms for ambiguous cues to `r round(mean(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Visual" & T1mean$PrepTarget$Target=="Visual"]),2)` ± `r round(stderr(T1mean$PrepTarget$RT[T1mean$PrepTarget$CueType=="Visual" & T1mean$PrepTarget$Target=="Visual"]),2)` ms for informative cues. The faster identification of trials with an informative cue suggest that top-down processes facilitated target processing.  

```{r Figuretwo, echo=FALSE, message=FALSE,fig.cap= 'Violin plot of RT to ambiguous and informatively cued targets, split by correct and erronous responses and target type. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean.'}
gridExtra::grid.arrange(Plots$Preparation$Accuracy,
Plots$Preparation$Modality)
```

Cues had the opposite influence on task accuracy. Auditory targets were incorrectly responded to in `r round(mean(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Ambiguous" & T1err$PrepTarget$Target=="Auditory"]),2)` ± `r round(stderr(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Ambiguous" & T1err$PrepTarget$Target=="Auditory"]),2)`% of trials with an uninformative cue and in `r round(mean(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Auditory" & T1err$PrepTarget$Target=="Auditory"]),2)` ± `r round(stderr(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Auditory" & T1err$PrepTarget$Target=="Auditory"]),2)`% with an informative cue. However, visual targets showed little difference in error rates between trials with ambiguous cues (`r round(mean(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Ambiguous" & T1err$PrepTarget$Target=="Visual"]),2)` ± `r round(stderr(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Ambiguous" & T1err$PrepTarget$Target=="Visual"]),2)`%) and trials with informative cues (`r round(mean(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Visual" & T1err$PrepTarget$Target=="Visual"]),2)` ± `r round(stderr(T1err$PrepTarget$ErrorRates[T1err$PrepTarget$CueType=="Visual" & T1err$PrepTarget$Target=="Visual"]),2)`%). As noted above, there was a probable ceiling effect on performance. However, omission rates showed some considerable differences between targets based upon whether they were cued or not. Omissions occurred on `r round(mean(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Ambiguous" & T1omm$PrepTarget$Target == "Auditory"]), 2)` ± `r round(stderr(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Ambiguous" & T1omm$PrepTarget$Target == "Auditory"]), 2)`% of auditory trials with an ambiguous cue. In comparison, informatively cued auditory trials contained `r round(mean(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Auditory" & T1omm$PrepTarget$Target == "Auditory"]), 2)` ± `r round(stderr(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Auditory" & T1omm$PrepTarget$Target == "Auditory"]), 2)`% omissions. A similar effect is seen with visual targets. Ambiguously cued visual targets contained `r round(mean(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Ambiguous" & T1omm$PrepTarget$Target == "Visual"]), 2)` ± `r round(stderr(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Ambiguous" & T1omm$PrepTarget$Target == "Visual"]), 2)`% of omissions, while informatively cued trials contained `r round(mean(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Ambiguous" & T1omm$PrepTarget$Target == "Visual"]), 2)` ± `r round(stderr(T1omm$PrepTarget$MissRates[T1omm$PrepTarget$CueType == "Ambiguous" & T1omm$PrepTarget$Target == "Visual"]), 2)`% omission trials.

### 3.1.3. Distraction Effects
To test whether participants were disturbed by the presentation of distract ors in a different modality, RTs from trials containing distractors were compared to RTs from the distractor absent trials. Informatively cued Auditory trials without distractors had mean RT of `r round(mean(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Absent" & T1mean$DistractionTarget$Target == "Auditory"]), 2)` ± `r round(stderr(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Absent" & T1mean$DistractionTarget$Target == "Auditory"]), 2)`ms, while Auditory trials with distraction had mean RT of `r round(mean(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Present" & T1mean$DistractionTarget$Target == "Auditory"]), 2)` ± `r round(stderr(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Present" & T1mean$DistractionTarget$Target == "Auditory"]), 2)`ms. Similarly, Visual targets had slower RT when distractions were present (`r round(mean(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Present" & T1mean$DistractionTarget$Target == "Visual"]), 2)` ± `r round(stderr(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Present" & T1mean$DistractionTarget$Target == "Visual"]), 2)`ms) compared to without (`r round(mean(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Absent" & T1mean$DistractionTarget$Target == "Visual"]), 2)` ± `r round(stderr(T1mean$DistractionTarget$RT[T1mean$DistractionTarget$Distractor == "Absent" & T1mean$DistractionTarget$Target == "Visual"]), 2)`ms). Presentation of a distractor in a different modality is detrimental for task performance and a mechanism for active inhibition of distractors could be beneficial during this task.

```{r Figurethree, echo=FALSE, message=FALSE, fig.cap= 'Violin plot of RT to targets with and without distraction, split by correct and erronous responses. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean.'}
gridExtra::grid.arrange(Plots$Distraction$Accuracy,
Plots$Distraction$Modality)
```

### 3.1.4. Pain Effects
The effect of pain on performance can be measured in a number of ways. Overall RT was relatively similar in the pain (`r round(mean(T1mean$Condition$RT[T1mean$Condition$Condition == "p"]), 2)` ± `r round(stderr(T1mean$Condition$RT[T1mean$Condition$Condition == "p"]), 2)`) vs no pain conditions (`r round(mean(T1mean$Condition$RT[T1mean$Condition$Condition == "np"]), 2)` ± `r round(stderr(T1mean$Condition$RT[T1mean$Condition$Condition == "np"]), 2)`). Likewise, overall error rates in the pain condition (`r round(mean(T1err$Condition$ErrorRates[T1err$Condition$Condition == "p"]), 2)` ± `r round(stderr(T1err$Condition$ErrorRates[T1err$Condition$Condition == "p"]), 2)`) were similar to the no pain condition (`r round(mean(T1err$Condition$ErrorRates[T1err$Condition$Condition == "np"]), 2)` ± `r round(stderr(T1err$Condition$ErrorRates[T1err$Condition$Condition == "np"]), 2)`). Omission rates were also found to be comparable across conditions (pain = `r round(mean(T1omm$Condition$MissRates[T1omm$Condition$Condition == "p"]), 2)` ± `r round(stderr(T1omm$Condition$MissRates[T1omm$Condition$Condition == "p"]), 2)`, no pain = `r round(mean(T1omm$Condition$MissRates[T1omm$Condition$Condition == "np"]), 2)` ± `r round(stderr(T1omm$Condition$MissRates[T1omm$Condition$Condition == "np"]), 2)`). Therefore an overall affect of condition on performance was not present. However, pain may influence specific effects of preparation and distraction.

```{r Figurefour, echo=FALSE, message=FALSE,fig.cap= 'Violin plot of RT with and without pain, split by correct and erronous responses. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean.'}
Plots$Condition$Accuracy
```

### 3.1.5. Pain Interactions
The RT benefit of visual targets was the same across pain (Auditory - Visual RT = `r round(mean(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Auditory"& T1mean$ConditionModality$Condition=="p"])-mean(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Visual" & T1mean$ConditionModality$Condition=="p"]),2)` ± `r round(stderr(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Auditory"& T1mean$ConditionModality$Condition=="p"])-stderr(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Visual" & T1mean$ConditionModality$Condition=="p"]),2)`) and no pain conditions (Auditory - Visual RT = `r round(mean(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Auditory"& T1mean$ConditionModality$Condition=="np"])-mean(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Visual" & T1mean$ConditionModality$Condition=="np"]),2)` ± `r round(stderr(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Auditory"& T1mean$ConditionModality$Condition=="np"])-stderr(T1mean$ConditionModality$RT[T1mean$ConditionModality$Target=="Visual" & T1mean$ConditionModality$Condition=="np"]),2)`).

```{r Figurefive, echo=FALSE, message=FALSE,fig.cap= 'Violin plot of RT with and without pain, split by Target. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean.'}
Plots$Condition$Modality
```

In the pain condition, there was only a small improvement in preparation costs. Ambiguous cues were `r round(mean(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType == "Ambiguous" & T1mean$ConditionPreparation$Condition == "p"]) - mean(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType != "Ambiguous" & T1mean$ConditionPreparation$Condition == "p"]),2)` ± `r round(stderr(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType == "Ambiguous" & T1mean$ConditionPreparation$Condition == "p"]) - stderr(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType != "Ambiguous" & T1mean$ConditionPreparation$Condition == "p"]),2)`ms slower compared to informatively cued trials in the pain condition. However, this difference was  `r round(mean(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType == "Ambiguous" & T1mean$ConditionPreparation$Condition == "np"]) - mean(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType != "Ambiguous" & T1mean$ConditionPreparation$Condition == "np"]),2)` ± `r round(stderr(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType == "Ambiguous" & T1mean$ConditionPreparation$Condition == "np"]) - stderr(T1mean$ConditionPreparation$RT[T1mean$ConditionPreparation$CueType != "Ambiguous" & T1mean$ConditionPreparation$Condition == "np"]),2)`ms in the no pain condition.

```{r Figuresix, echo=FALSE, fig.cap='Violin plot of RT with and without pain, split by cue type. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean.', message=FALSE}
Plots$Condition$Preparation
```

Distraction effects showed little differences between the pain condition (`r round(mean(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Present" & T1mean$ConditionDistraction$Condition == "p"]) - mean(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Absent" & T1mean$ConditionDistraction$Condition == "p"]),2)` ± `r round(mean(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Present" & T1mean$ConditionDistraction$Condition == "p"]) - stderr(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Absent" & T1mean$ConditionDistraction$Condition == "p"]),2)`) and no pain conditions (`r round(mean(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Present" & T1mean$ConditionDistraction$Condition == "np"]) - stderr(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Absent" & T1mean$ConditionDistraction$Condition == "np"]),2)` ± `r round(mean(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Present" & T1mean$ConditionDistraction$Condition == "np"]) - stderr(T1mean$ConditionDistraction$RT[T1mean$ConditionDistraction$Distractor == "Absent" & T1mean$ConditionDistraction$Condition == "np"]),2)`).

```{r Figureseven, echo=FALSE, message=FALSE,fig.cap= 'Violin plot of RT with and without pain, split by prescence of distractor. Median RT is presented as a horizontal line in each violin, with error bars displaying the standard error of the mean.'}
Plots$Condition$Distraction
```

## 3.1. Behavioural Models
```{r RT Tests, eval=FALSE, include=FALSE}
## Just do this in JASP ##

## Linear Models take longer than straight ANOVAs?
system.time(
RTBayes_all <-
  BayesFactor::anovaBF(
    RT ~ Target * CueType * Condition + PartID,
    data = Trialdata[!is.na(Trialdata$RT),],
    whichRandom = "PartID",
    progress = T,
    iterations = 1000,
    whichModels = "top"
    ))


system.time(
RTBayes <-
  BayesFactor::anovaBF(
    RT ~ Target * CueType + PartID,
    data = Trialdata[!is.na(Trialdata$RT),],
    whichRandom = "PartID",
    progress = T,
    iterations = 10000,
    whichModels = "top"

    ))

# 10 =    user  system elapsed 
#       115.38    0.21  119.02 
 
# 5 =    user  system elapsed 
#      115.34    0.32  116.86 

# Turn into bf_ format
bf_model <- bayesfactor_models(RTBayes_all)
bayestestR::bayesfactor_inclusion(bf_model,match_models = F)

bayestestR::bf_inclusion(RTBayes_all)

RTBayeslm_NullComparison <- head(RTBayeslm_all)/max(RTBayeslm_all)
## See differences between most supported model
plot(RTBayeslm_NullComparison)
```

```{r PAF Anal}
## Subjects
EEGSubj <- as.character(Subjidx)
EEGSubj[length(EEGSubj)+1] <- "CLP130"
EEGSubj <- EEGSubj[c(1:29,32,30,31)]

## Electrodes
electrodes <- read.csv("EEG_Output/ElectrodeLabels.csv")

## Analysis of Alpha EEG Data ##
Alpha <- rmatio::read.mat("EEG_Output/ImpAlphaPower.mat")
Alpha[["np"]] <- data.frame(Alpha$AlphaPower[,1,])
names(Alpha[["np"]]) <- electrodes[!electrodes=="Cz"]
Alpha[["np"]]$PartID <- EEGSubj
Alpha[["np"]]$Condition <- "np"
Alpha[["np"]][Alpha[["np"]]==0] <- NA
Alpha[["p"]] <- data.frame(Alpha$AlphaPower[,2,])
names(Alpha[["p"]]) <- electrodes[!electrodes=="Cz"]
Alpha[["p"]]$PartID <- EEGSubj
Alpha[["p"]]$Condition <- "p"
Alpha[["p"]][Alpha[["p"]]==0] <- NA

AlphaPower <- rbind(Alpha[["np"]],Alpha[["p"]])
AlphaPower$Variable <- "AlphaPower"

## Analysis of Peak Alpha Frequency EEG Data ##
PAF <- rmatio::read.mat("EEG_Output/ImpPeakFrequency.mat")
PAF[["np"]] <- data.frame(PAF$PeakFrequency[,1,])
names(PAF[["np"]]) <- electrodes[!electrodes=="Cz"]
PAF[["np"]]$PartID <- EEGSubj
PAF[["np"]]$Condition <- "np"
PAF[["np"]][PAF[["np"]]==0] <- NA
PAF[["p"]] <- data.frame(PAF$PeakFrequency[,2,])
names(PAF[["p"]]) <- electrodes[!electrodes=="Cz"]
PAF[["p"]]$PartID <- EEGSubj
PAF[["p"]]$Condition <- "p"
PAF[["p"]][PAF[["p"]]==0] <- NA

PAF <- rbind(PAF[["np"]],PAF[["p"]])
PAF$Variable <- "PAF"

# ## Analysis of Spectra EEG Data ##
# PAF <- rmatio::read.mat("EEG_Output/ImpPeakFrequency.mat")
# PAF[["np"]] <- data.frame(PAF$PeakFrequency[,1,])
# names(PAF[["np"]]) <- electrodes[!electrodes=="Cz"]
# PAF[["np"]]$PartID <- EEGSubj
# PAF[["np"]]$Condition <- "np"
# PAF[["np"]][PAF[["np"]]==0] <- NA
# PAF[["p"]] <- data.frame(PAF$PeakFrequency[,2,])
# names(PAF[["p"]]) <- electrodes[!electrodes=="Cz"]
# PAF[["p"]]$PartID <- EEGSubj
# PAF[["p"]]$Condition <- "p"
# PAF[["p"]][PAF[["p"]]==0] <- NA
# 
# PAF <- rbind(PAF[["np"]],PAF[["p"]])
# PAF$Variable <- "PAF"

# Combine and make a long dataset
EEG_Measures <- rbind(AlphaPower,PAF)
write.csv(EEG_Measures,file = "Output/EEG_Measures.csv",row.names = F)
# Make Long for plotting
EEG_Plot <- reshape2::melt(EEG_Measures,
                           id.vars = c("PartID","Condition","Variable"),
                           value.name = "Amplitude",
                           variable.name = "Site")
write.csv(EEG_Plot,file = "Output/EEG_Measureslong.csv",row.names = F)

```

```{r Plot EEG Measures}
SOI <- c("Fz","FCz","Cz","C3","C4","CPz","Pz")
  EEG_Plot %>% 
  dplyr::filter(Variable=="AlphaPower",Site %in% SOI) %>% 
  ggplot(aes(y = Amplitude,
             colour = Condition,
             x = Site)) +
    geom_jitter()+
  geom_violin(alpha = 0,
              scale = "width",
              adjust = .5,
              draw_quantiles = c(.5)) +
  # scale_fill_manual(name = "Condition",
  #                   labels = c("No Pain", "Pain"),
  #                   values = cbbPalette) +
      scale_colour_manual(name = "Condition",
                    labels = c("No Pain", "Pain"),
                    values = cbbPalette) +
  ylab("Hz") +
  theme_classic()
  ggsave("Output/AlphaPlot.tiff")
  # geom_errorbar(data = wse[["TargetAccuracy"]],
  #               aes(ymin = RT - se,
  #                   ymax = RT + se),
  #               lwd = .3,
  #               width = .5,
  #               position = position_dodge(.9))

```

